
%=============================================
% 				INTRODUCTION
%=============================================

@incollection{bond_fires_2017,
	title = {Fires, {Ecological} {Effects} of},
	isbn = {978-0-12-809633-8},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128096338020987},
	language = {en},
	urldate = {2022-08-02},
	booktitle = {Reference {Module} in {Life} {Sciences}},
	publisher = {Elsevier},
	author = {Bond, W.J. and Keane, R.E.},
	year = {2017},
	doi = {10.1016/B978-0-12-809633-8.02098-7},
	pages = {B9780128096338020987},
	file = {Bond and Keane - 2017 - Fires, Ecological Effects of ☆.pdf:/home/mjpc13/Zotero/storage/6WZ5VI5E/Bond and Keane - 2017 - Fires, Ecological Effects of ☆.pdf:application/pdf},
}

@article{turco_decreasing_2016,
	title = {Decreasing {Fires} in {Mediterranean} {Europe}},
	volume = {11},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0150663},
	doi = {10.1371/journal.pone.0150663},
	language = {en},
	number = {3},
	urldate = {2022-08-02},
	journal = {PLOS ONE},
	author = {Turco, Marco and Bedia, Joaquín and Di Liberto, Fabrizio and Fiorucci, Paolo and von Hardenberg, Jost and Koutsias, Nikos and Llasat, Maria-Carmen and Xystrakis, Fotios and Provenzale, Antonello},
	editor = {Carcaillet, Christopher},
	month = mar,
	year = {2016},
	pages = {e0150663},
	file = {Full Text:/home/mjpc13/Zotero/storage/CCH8LRYH/Turco et al. - 2016 - Decreasing Fires in Mediterranean Europe.pdf:application/pdf},
}

@book{european_commission_joint_research_centre_forest_2021,
	address = {LU},
	title = {Forest {Fires} in {Europe}, {Middle} {East} and {North} {Africa} 2020.},
	url = {https://data.europa.eu/doi/10.2760/059331},
	language = {eng},
	urldate = {2022-08-02},
	publisher = {Publications Office},
	author = {{European Commission. Joint Research Centre.}},
	year = {2021},
}

@misc{ IFR_robot_report_2020,
    author = "{Internation Federation of Robotics}",
    title = "World Robotics Report 2020",
    year = "2020",
    howpublished = "\url{https://ifr.org/ifr-press-releases/news/record-2.7-million-robots-work-in-factories-around-the-globe}"
  }

@article{parker_robotics_2016,
        title = {Robotics in forestry},
        volume = {60},
        abstract = {New technologies are increasingly being integrated into everyday tasks to assist users and could radically change the nature of how industries operate. Forest harvesting operations have been traditionally considered physically demanding and potentially dangerous, with forest workers on foot exposed to heavy and fast-moving trees, logs and machinery. Many tasks in forestry have already been mechanised to reduce hazards to the worker and increase productivity. For example, the axe was replaced by the chainsaw, which was replaced by the harvester. Workers on log landings have been displaced by delimbing machines and breakers-out by grapple carriages.},
        journal = {New Zealand Journal of Forestry},
        author = {Parker, Richard and Bayne, Karen and Clinton, Peter},
        month = feb,
        year = {2016},
        pages = {8--14},
        file = {Full Text PDF:/home/mjpc13/Zotero/storage/VLVIJL73/Parker et al. - 2016 - Robotics in forestry.pdf:application/pdf},
}

%---ROBOTS---
%Monitoring and preservation
@inproceedings{lam_flexible_2011,
        title = {A flexible tree climbing robot: {Treebot} - design and implementation},
        shorttitle = {A flexible tree climbing robot},
        doi = {10.1109/ICRA.2011.5979833},
        abstract = {This paper proposed a novel tree climbing robot "Treebot" that has high maneuverability on an irregular tree environment and surpasses the state of the art tree climbing robots. Treebot's body is a novel continuum maneuver structure that has high degrees of freedom and superior extension ability. Treebot also equips with a pair of omni-directional tree grippers that enable Treebot to adhere on a wide variety of trees with a wide range of gripping curvature. By combining these two novel designs, Treebot is able to reach many places on trees including branches. Treebot can maneuver on a complex tree environment, but only five actuators are used in the mechanism. As a result, Treebot can keep in compact size and lightweight. Although Treebot weighs only 600 grams, it has payload capability of 1.75 kg which is nearly three times of its own weight. On top of that, the special design of the gripper permits zero energy consumption in static gripping. Numerous experiments have been conducted on real trees. Experimental results reveal that Treebot has excellent climbing performance on a wide variety of trees.},
        booktitle = {2011 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
        author = {Lam, Tin Lun and Xu, Yangsheng},
        month = may,
        year = {2011},
        note = {ISSN: 1050-4729},
        keywords = {Climbing robots, Force, Grippers, Manipulators, Springs, Vegetation},
        pages = {5849--5854},
        file = {IEEE Xplore Full Text PDF:/home/mjpc13/Zotero/storage/W278HD8W/Lam and Xu - 2011 - A flexible tree climbing robot Treebot - design a.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mjpc13/Zotero/storage/GEVWMV3C/5979833.html:text/html},
}

@techreport{jelavic_towards_2021,
        title = {Towards {Autonomous} {Robotic} {Precision} {Harvesting}: {Mapping}, {Localization}, {Planning} and {Control} for a {Legged} {Tree} {Harvester}},
        shorttitle = {Towards {Autonomous} {Robotic} {Precision} {Harvesting}},
        url = {http://arxiv.org/abs/2104.10110},
        abstract = {This paper presents an integrated system for performing precision harvesting missions using a legged harvester. Our harvester performs a challenging task of autonomous navigation and tree grabbing in a confined, GPS denied forest environment. Strategies for mapping, localization, planning, and control are proposed and integrated into a fully autonomous system. The mission starts with a human mapping the area of interest using a custom-made sensor module. Subsequently, a human expert selects the trees for harvesting. The sensor module is then mounted on the machine and used for localization within the given map. A planning algorithm searches for both an approach pose and a path in a single path planning problem. We design a path following controller leveraging the legged harvester's capabilities for negotiating rough terrain. Upon reaching the approach pose, the machine grabs a tree with a general-purpose gripper. This process repeats for all the trees selected by the operator. Our system has been tested on a testing field with tree trunks and in a natural forest. To the best of our knowledge, this is the first time this level of autonomy has been shown on a full-size hydraulic machine operating in a realistic environment.},
        number = {arXiv:2104.10110},
        urldate = {2022-09-12},
        institution = {arXiv},
        author = {Jelavic, Edo and Jud, Dominic and Egli, Pascal and Hutter, Marco},
        month = nov,
        year = {2021},
        note = {arXiv:2104.10110 [cs, eess]
type: article},
        keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
        file = {arXiv Fulltext PDF:/home/mjpc13/Zotero/storage/KGMX9Z8A/Jelavic et al. - 2021 - Towards Autonomous Robotic Precision Harvesting M.pdf:application/pdf;arXiv.org Snapshot:/home/mjpc13/Zotero/storage/FK9KVQZD/2104.html:text/html},
}

@article{notomista_slothbot_2019,
        title = {The {SlothBot}: {A} {Novel} {Design} for a {Wire}-{Traversing} {Robot}},
        volume = {PP},
        shorttitle = {The {SlothBot}},
        doi = {10.1109/LRA.2019.2899593},
        abstract = {This paper presents the SlothBot, a wire-traversing robot envisioned for long-term environmental monitoring applications. The SlothBot is a solar-powered, slow-paced, energy-efficient robot-hence its name-capable of moving on a mesh of wires by switching between branching wires. Unlike ground mobile robots or aerial robots employed in environmental monitoring applications, the use of wire-traversing robots allows for longer-term deployment because of the significantly lower energy consumption. Wire-traversing, coupled with the use of solar panels, facilitates the self-sustainability of the SlothBot. Locomotion and wire-switching maneuvers are performed in a fail-safe fashion, inasmuch the robot is always firmly attached to the wires, even when switching between branching wires. This is achieved by employing a two-body structure featuring an actuated decoupling mechanism. In this paper we show the design and the motion control of the SlothBot, together with the results of long-term monitoring experiments.},
        journal = {IEEE Robotics and Automation Letters},
        author = {Notomista, Gennaro and Emam, Yousef and Egerstedt, Magnus},
        month = feb,
        year = {2019},
        pages = {1--1},
}

@inproceedings{couceiro_semfire_2019,
        title = {{SEMFIRE}: {Towards} a new generation of forestry maintenance multi-robot systems},
        shorttitle = {{SEMFIRE}},
        doi = {10.1109/SII.2019.8700403},
        abstract = {Europe has been affected by an alarming number of wildfires every year, ravaging nearly half a million hectares of forestry areas and resulting in an unacceptable amount of human losses. The year 2017 was one of the worst ever recorded, with devastating wildfires raging across the globe. Bearing these shocking facts in mind, this position paper aims to lay the foundations of crucial new upcoming research in the field of forestry robotics by presenting an overview of the SEMFIRE project. SEMFIRE proposes the development of a robotic system designed to reduce the accumulation of combustible material in forests, thus assisting in landscaping maintenance tasks for wildfire prevention. This paper describes the multi-robot system envisaged by SEMFIRE, combined with pervasive local positioning, multi-robot navigation and coordination in forests, and an innovative artificial perception architecture.},
        booktitle = {2019 {IEEE}/{SICE} {International} {Symposium} on {System} {Integration} ({SII})},
        author = {Couceiro, Micael S. and Portugal, David and Ferreira, João F. and Rocha, Rui P.},
        month = jan,
        year = {2019},
        note = {ISSN: 2474-2325},
        keywords = {Fires, Forestry, Fuels, Maintenance engineering, Robot kinematics, Vegetation mapping},
        pages = {270--276},
        file = {IEEE Xplore Full Text PDF:/home/mjpc13/Zotero/storage/Y6W57LYG/Couceiro et al. - 2019 - SEMFIRE Towards a new generation of forestry main.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mjpc13/Zotero/storage/JJT3CBGI/8700403.html:text/html},
}

% Fight wildfire
@misc{hydra, 
    author = {Milrem Robotics},
    title = {Multiscope Rescue with Hydra},
    year = 2022,
    url = {https://milremrobotics.com/product/multiscope-rescue-hydra/ },
    urldate = {2022-09-14}
}

@misc{hose_cartridge, 
    author = {Milrem Robotics},
    title = {Multiscope Rescue Hose Cartridge},
    year = 2022,
    url = {https://milremrobotics.com/product/firehouse-container/},
    urldate = {2022-09-14}
}
@misc{noauthor_firefighting_2014,
        title = {Firefighting {Robotic} {Vehicle} {System}},
        url = {https://www.fireapparatusmagazine.com/fire-apparatus/firefighting-robotic-vehicle-system/},
        abstract = {The autonomous technology can support suppresstion, trenching, hazmat, mop-up, situational awareness, communications, logistics, casualty or injury evacuation, and three-dimensional mapping and navigation. F},
        language = {en-US},
        urldate = {2022-09-14},
        journal = {Fire Apparatus: Fire trucks, fire engines, emergency vehicles, and firefighting equipment},
        month = aug,
        year = {2014},
        file = {Snapshot:/home/mjpc13/Zotero/storage/8PRY7EF5/firefighting-robotic-vehicle-system.html:text/html},
}

%Pruning, Cutting, Harvest
@misc{noauthor_multiscope_nodate,
        title = {Multiscope {Forester} {Planter}},
        url = {https://milremrobotics.com/product/robotic-forester-planter/},
        abstract = {The Multiscope Forester Planter is equipped with a modular planting payload with a capacity of 380 seedlings. Its planting speed is around 5-6.5 hours per hectare depending on the tree species and the terrain. The system is designed for a temperate climate zone.},
        language = {en-GB},
        urldate = {2022-09-14},
        journal = {Milrem},
        file = {Snapshot:/home/mjpc13/Zotero/storage/WTF3RJCN/robotic-forester-planter.html:text/html},
}

@article{molina_aerial_2017,
        title = {Aerial pruning mechanism, initial real environment test},
        volume = {4},
        issn = {2197-3768},
        doi = {10.1186/s40638-017-0073-3},
        abstract = {In this research, a pruning mechanism for aerial pruning tasks is tested in a real environment. Since the final goal of the aerial pruning robot will be to prune tree branches close to power lines, some experiments related to wireless communication and pruning performance were conducted. The experiments consisted of testing the communication between two XBee RF modules for monitoring purposes as well as testing the speed control of the circular saw used for pruning tree branches. Results show that both the monitoring and the pruning tasks were successfully done in a real environment.},
        language = {eng},
        number = {1},
        journal = {Robotics and Biomimetics},
        author = {Molina, Javier and Hirai, Shinichi},
        year = {2017},
        pmid = {29170729},
        pmcid = {PMC5681622},
        keywords = {Aerial robot, Grasping, Pruning, Skew-gripper},
        pages = {15},
        file = {Full Text:/home/mjpc13/Zotero/storage/Y7KI78G4/Molina and Hirai - 2017 - Aerial pruning mechanism, initial real environment.pdf:application/pdf},
}

@article{zhang_rubber-tapping_2019,
        title = {A {Rubber}-{Tapping} {Robot} {Forest} {Navigation} and {Information} {Collection} {System} {Based} on {2D} {LiDAR} and a {Gyroscope}},
        volume = {19},
        issn = {1424-8220},
        doi = {10.3390/s19092136},
        abstract = {Natural rubber is widely used in human life because of its excellent quality. At present, manual tapping is still the main way to obtain natural rubber. There is a sore need for intelligent tapping devices in the tapping industry, and the autonomous navigation technique is of great importance to make rubber-tapping devices intelligent. To realize the autonomous navigation of the intelligent rubber-tapping platform and to collect information on a rubber forest, the sparse point cloud data of tree trunks are extracted by the low-cost LiDAR and a gyroscope through the clustering method. The point cloud is fitted into circles by the Gauss-Newton method to obtain the center point of each tree. Then, these center points are threaded through the Least Squares method to obtain the straight line, which is regarded as the navigation path of the robot in this forest. Moreover, the Extended Kalman Filter (EKF) algorithm is adopted to obtain the robot's position. In a forest with different row spacings and plant spacings, the heading error and lateral error of this robot are analyzed and a Fuzzy Controller is applied for the following activities: walking along one row with a fixed lateral distance, stopping at fixed points, turning from one row into another, and collecting information on plant spacing, row spacing, and trees' diameters. Then, according to the collected information, each tree's position is calculated, and the geometric feature map is constructed. In a forest with different row spacings and plant spacings, three repeated tests have been carried out at an initial speed of 0.3 m/s. The results show that the Root Mean Square (RMS) lateral errors are less than 10.32 cm, which shows that the proposed navigation method provides great path tracking. The fixed-point stopping range of the robot can meet the requirements for automatic rubber tapping of the mechanical arm, and the average stopping error is 12.08 cm. In the geometric feature map constructed by collecting information, the RMS radius errors are less than 0.66 cm, and the RMS plant spacing errors are less than 11.31 cm. These results show that the method for collecting information and constructing a map recursively in the process of navigation proposed in the paper provides a solution for forest information collection. The method provides a low-cost, real-time, and stable solution for forest navigation of automatic rubber tapping equipment, and the collected information not only assists the automatic tapping equipment to plan the tapping path, but also provides a basis for the informationization and precise management of a rubber plantation.},
        language = {eng},
        number = {9},
        journal = {Sensors (Basel, Switzerland)},
        author = {Zhang, Chunlong and Yong, Liyun and Chen, Ying and Zhang, Shunlu and Ge, Luzhen and Wang, Song and Li, Wei},
        month = may,
        year = {2019},
        pmid = {31072051},
        pmcid = {PMC6540314},
        keywords = {2D LiDAR, gyroscope, information collection, map construction, navigation},
        pages = {E2136},
        file = {Full Text:/home/mjpc13/Zotero/storage/9LA3RMS4/Zhang et al. - 2019 - A Rubber-Tapping Robot Forest Navigation and Infor.pdf:application/pdf},
}

%=============================================
% 		BACKGROUND
%=============================================

@inproceedings{rublee_orb_2011,
        title = {{ORB}: {An} efficient alternative to {SIFT} or {SURF}},
        shorttitle = {{ORB}},
        doi = {10.1109/ICCV.2011.6126544},
        abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
        booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
        author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
        month = nov,
        year = {2011},
        note = {ISSN: 2380-7504},
        keywords = {Boats},
        pages = {2564--2571},
        file = {IEEE Xplore Full Text PDF:/home/mjpc13/Zotero/storage/AECXPVV8/Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mjpc13/Zotero/storage/FH2N5FZJ/6126544.html:text/html},
}
%Visual Odometry with Deep Learning
@inproceedings{liu_visual_2021,
        title = {Visual {Odometry} {Algorithm} {Based} on {Deep} {Learning}},
        url = {https://dx.doi.org/10.1109/icivc52351.2021.9526975},
        doi = {10.1109/icivc52351.2021.9526975},
        publisher = {IEEE},
        author = {Liu, Hao and Huang, Dan Dan and Geng, Zhen Ye},
        year = {2021},
}

%Scan mathing image
@article{konecny_scan_2019,
        title = {Scan {Matching} by {Cross}-{Correlation} and {Differential} {Evolution}},
        volume = {8},
        issn = {2079-9292},
        url = {https://dx.doi.org/10.3390/electronics8080856},
        doi = {10.3390/electronics8080856},
        number = {8},
        journal = {Electronics},
        author = {Konecny, Jaromir and Kromer, Pavel and Prauzek, Michal and Musilek, Petr},
        year = {2019},
        note = {Publisher: MDPI AG},
        pages = {856},
}

%---OCTOMAP---
@article{hornung_octomap_2013,
        title = {{OctoMap}: an efficient probabilistic {3D} mapping framework based on octrees},
        volume = {34},
        issn = {0929-5593},
        url = {https://dx.doi.org/10.1007/s10514-012-9321-0},
        doi = {10.1007/s10514-012-9321-0},
        number = {3},
        journal = {Autonomous Robots},
        author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
        year = {2013},
        note = {Publisher: Springer Science and Business Media LLC},
        pages = {189--206},
}

%---SLAM-ALGORITHMS---
@inproceedings{wang_upf-ukf_2007,
        title = {A {UPF}-{UKF} {Framework} {For} {SLAM}},
        isbn = {1050-4729},
        url = {https://dx.doi.org/10.1109/robot.2007.363562},
        doi = {10.1109/robot.2007.363562},
        publisher = {IEEE},
        author = {Wang, Xiang and Zhang, Hong},
        year = {2007},
}

@article{thrun_fastslam_nodate,
        title = {{FastSLAM}: {An} {Efﬁcient} {Solution} to the {Simultaneous} {Localization} {And} {Mapping} {Problem} with {Unknown} {Data} {Association}},
        abstract = {This article provides a comprehensive description of FastSLAM, a new family of algorithms for the simultaneous localization and mapping problem, which speciﬁcally address hard data association problems. The algorithm uses a particle ﬁlter for sampling robot paths, and extended Kalman ﬁlters for representing maps acquired by the vehicle. This article presents two variants of this algorithm, the original algorithm along with a more recent variant that provides improved performance in certain operating regimes. In addition to a mathematical derivation of the new algorithm, we present a proof of convergence and experimental results on its performance on real-world data.},
        language = {en},
        author = {Thrun, Sebastian and Montemerlo, Michael and Koller, Daphne and Wegbreit, Ben and Nieto, Juan and Nebot, Eduardo},
        pages = {48},
        file = {Thrun et al. - FastSLAM An Efﬁcient Solution to the Simultaneous.pdf:/home/mjpc13/Zotero/storage/QM9YALFY/Thrun et al. - FastSLAM An Efﬁcient Solution to the Simultaneous.pdf:application/pdf},
}

@article{lu_globally_1997,
        title = {Globally {Consistent} {Range} {Scan} {Alignment} for {Environment} {Mapping}},
        volume = {4},
        issn = {0929-5593},
        url = {https://dx.doi.org/10.1023/a:1008854305733},
        doi = {10.1023/a:1008854305733},
        number = {4},
        journal = {Autonomous Robots},
        author = {Lu, F. and Milios, E.},
        year = {1997},
        note = {Publisher: Springer Science and Business Media LLC},
        pages = {333--349},
}

@article{grisetti_tutorial_2010,
        title = {A {Tutorial} on {Graph}-{Based} {SLAM}},
        volume = {2},
        issn = {1939-1390},
        url = {https://dx.doi.org/10.1109/mits.2010.939925},
        doi = {10.1109/mits.2010.939925},
        number = {4},
        journal = {IEEE Intelligent Transportation Systems Magazine},
        author = {Grisetti, G and Kummerle, R and Stachniss, C and Burgard, W},
        year = {2010},
        note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
        pages = {31--43},
}

%Gmapping
@article{grisetti_improved_2007,
        title = {Improved {Techniques} for {Grid} {Mapping} {With} {Rao}-{Blackwellized} {Particle} {Filters}},
        volume = {23},
        issn = {1552-3098},
        url = {https://dx.doi.org/10.1109/tro.2006.889486},
        doi = {10.1109/tro.2006.889486},
        number = {1},
        journal = {IEEE Transactions on Robotics},
        author = {Grisetti, Giorgio and Stachniss, Cyrill and Burgard, Wolfram},
        year = {2007},
        note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
        pages = {34--46},
}

%RTAB-Map
@article{labbe_rtab-map_2019,
        title = {{RTAB}-{Map} as an open-source lidar and visual simultaneous localization and mapping library for large-scale and long-term online operation: {LABBÉ} {\textless}span style="font-variant:small-caps;"{\textgreater}and{\textless}/span{\textgreater} {MICHAUD}},
        volume = {36},
        issn = {15564959},
        shorttitle = {{RTAB}-{Map} as an open-source lidar and visual simultaneous localization and mapping library for large-scale and long-term online operation},
        url = {https://onlinelibrary.wiley.com/doi/10.1002/rob.21831},
        doi = {10.1002/rob.21831},
        abstract = {Distributed as an open source library since 2013, RTAB-Map started as an appearancebased loop closure detection approach with memory management to deal with large-scale and long-term online operation. It then grew to implement Simultaneous Localization and Mapping (SLAM) on various robots and mobile platforms. As each application brings its own set of contraints on sensors, processing capabilities and locomotion, it raises the question of which SLAM approach is the most appropriate to use in terms of cost, accuracy, computation power and ease of integration. Since most of SLAM approaches are either visual or lidar-based, comparison is diﬃcult. Therefore, we decided to extend RTAB-Map to support both visual and lidar SLAM, providing in one package a tool allowing users to implement and compare a variety of 3D and 2D solutions for a wide range of applications with diﬀerent robots and sensors. This paper presents this extended version of RTAB-Map and its use in comparing, both quantitatively and qualitatively, a large selection of popular real-world datasets (e.g., KITTI, EuRoC, TUM RGB-D, MIT Stata Center on PR2 robot), outlining strengths and limitations of visual and lidar SLAM conﬁgurations from a practical perspective for autonomous navigation applications.},
        language = {en},
        number = {2},
        urldate = {2022-10-06},
        journal = {Journal of Field Robotics},
        author = {Labbé, Mathieu and Michaud, François},
        month = mar,
        year = {2019},
        pages = {416--446},
        file = {Labbé and Michaud - 2019 - RTAB-Map as an open-source lidar and visual simult.pdf:/home/mjpc13/Zotero/storage/QPA9PQVS/Labbé and Michaud - 2019 - RTAB-Map as an open-source lidar and visual simult.pdf:application/pdf},
}

%GTSAM
@software{gtsam,
  author       = {Frank Dellaert and Richard Roberts and Varun Agrawal and Alex Cunningham and Chris Beall and Duy-Nguyen Ta and Fan Jiang and lucacarlone and nikai and Jose Luis Blanco-Claraco and Stephen Williams and ydjian and John Lambert and Andy Melim and Zhaoyang Lv and Akshay Krishnan and Jing Dong and Gerry Chen and Krunal Chande and balderdash-devil and DiffDecisionTrees and Sungtae An and mpaluri and Ellon Paiva Mendes and Mike Bosse and Akash Patel and Ayush Baid and Paul Furgale and matthewbroadwaynavenio and roderick-koehle},
  title        = {borglab/gtsam},
  month        = may,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {4.2a7},
  doi          = {10.5281/zenodo.5794541},
  url          = {https://doi.org/10.5281/zenodo.5794541}
}

%g2o
@inproceedings{kummerle_g2o_2011,
        address = {Shanghai, China},
        title = {G$^{\textrm{2}}$o: {A} general framework for graph optimization},
        isbn = {978-1-61284-386-5},
        shorttitle = {G$^{\textrm{2}}$o},
        url = {http://ieeexplore.ieee.org/document/5979949/},
        doi = {10.1109/ICRA.2011.5979949},
        abstract = {Many popular problems in robotics and computer vision including various types of simultaneous localization and mapping (SLAM) or bundle adjustment (BA) can be phrased as least squares optimization of an error function that can be represented by a graph. This paper describes the general structure of such problems and presents g2o, an open-source C++ framework for optimizing graph-based nonlinear error functions. Our system has been designed to be easily extensible to a wide range of problems and a new problem typically can be speciﬁed in a few lines of code. The current implementation provides solutions to several variants of SLAM and BA. We provide evaluations on a wide range of real-world and simulated datasets. The results demonstrate that while being general g2o offers a performance comparable to implementations of stateof-the-art approaches for the speciﬁc problems.},
        language = {en},
        urldate = {2022-10-06},
        booktitle = {2011 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
        publisher = {IEEE},
        author = {Kummerle, Rainer and Grisetti, Giorgio and Strasdat, Hauke and Konolige, Kurt and Burgard, Wolfram},
        month = may,
        year = {2011},
        pages = {3607--3613},
        file = {Kummerle et al. - 2011 - G2o A general framework for graph opti.pdf:/home/mjpc13/Zotero/storage/7V4JT88B/Kummerle et al. - 2011 - G2o A general framework for graph opti.pdf:application/pdf},
}

%TORO
@article{grisetti_nonlinear_2009,
        title = {Nonlinear {Constraint} {Network} {Optimization} for {Efficient} {Map} {Learning}},
        volume = {10},
        issn = {1524-9050, 1558-0016},
        url = {http://ieeexplore.ieee.org/document/5164927/},
        doi = {10.1109/TITS.2009.2026444},
        abstract = {Learning models of the environment is one of the fundamental tasks of mobile robots since maps are needed for a wide range of robotic applications, such as navigation and transportation tasks, service robotic applications, and several others. In the past, numerous efﬁcient approaches to map learning have been proposed. Most of them, however, assume that the robot lives on a plane. In this paper, we present a highly efﬁcient maximum likelihood approach that is able to solve 3D as well as 2D problems. Our approach addresses the so-called graph-based formulation of the simultaneous localization and mapping (SLAM) and can be seen as an extension of Olson’s algorithm [27] towards non-ﬂat environments. It applies a novel parameterization of the nodes of the graph that signiﬁcantly improves the performance of the algorithm and can cope with arbitrary network topologies. The latter allows us to bound the complexity of the algorithm to the size of the mapped area and not to the length of the trajectory. Furthermore, our approach is able to appropriately distribute the roll, pitch and yaw error over a sequence of poses in 3D mapping problems. We implemented our technique and compared it to multiple other graph-based SLAM solutions. As we demonstrate in simulated and in real world experiments, our method converges faster than the other approaches and yields accurate maps of the environment.},
        language = {en},
        number = {3},
        urldate = {2022-10-06},
        journal = {IEEE Transactions on Intelligent Transportation Systems},
        author = {Grisetti, G. and Stachniss, C. and Burgard, W.},
        month = sep,
        year = {2009},
        pages = {428--439},
        file = {Grisetti et al. - 2009 - Nonlinear Constraint Network Optimization for Effi.pdf:/home/mjpc13/Zotero/storage/3QW9EC6W/Grisetti et al. - 2009 - Nonlinear Constraint Network Optimization for Effi.pdf:application/pdf},
}

%LIO-Mapping
@inproceedings{ye2019tightly,
  title={Tightly Coupled 3D Lidar Inertial Odometry and Mapping},
  author={Ye, Haoyang and Chen, Yuying and Liu, Ming},
  booktitle={2019 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2019},
  organization={IEEE}
}

@inproceedings{kim_scan_2018,
        title = {Scan {Context}: {Egocentric} {Spatial} {Descriptor} for {Place} {Recognition} {Within} {3D} {Point} {Cloud} {Map}},
        url = {https://dx.doi.org/10.1109/iros.2018.8593953},
        doi = {10.1109/iros.2018.8593953},
        publisher = {IEEE},
        author = {Kim, Giseop and Kim, Ayoung},
        year = {2018},
}

%LIO-SAM
@inproceedings{liosam2020shan,
  title={LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping},
  author={Shan, Tixiao and Englot, Brendan and Meyers, Drew and Wang, Wei and Ratti, Carlo and Rus Daniela},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5135-5142},
  year={2020},
  organization={IEEE}
}

%Cartographer
@inproceedings{hess_real-time_2016,
        title = {Real-{Time} {Loop} {Closure} in {2D} {LIDAR} {SLAM}},
        booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
        author = {Hess, Wolfgang and Kohler, Damon and Rapp, Holger and Andor, Daniel},
        year = {2016},
        pages = {1271--1278},
        file = {Full Text PDF:/home/mjpc13/Zotero/storage/PQTBZCM9/Hess et al. - 2016 - Real-Time Loop Closure in 2D LIDAR SLAM.pdf:application/pdf},
}

%Hector SLAM
@inproceedings{kohlbrecher_flexible_2011,
        title = {A flexible and scalable {SLAM} system with full {3D} motion estimation},
        url = {https://dx.doi.org/10.1109/ssrr.2011.6106777},
        doi = {10.1109/ssrr.2011.6106777},
        publisher = {IEEE},
        author = {Kohlbrecher, Stefan and Von Stryk, Oskar and Meyer, Johannes and Klingauf, Uwe},
        year = {2011},
}



%=============================================
% 		RELATED WORK
%=============================================

%---Proprietary-Apparatus---

@misc{libackpack_DGC50,
        title = {{LiBackpack} {DGC50}-{GreenValley} {International}},
        url = {https://greenvalleyintl.com/LiBackpackDGC50/},
        urldate = {2022-09-19},
        file = {LiBackpack DGC50-GreenValley International:/home/mjpc13/Zotero/storage/W8X6MHB5/LiBackpackDGC50.html:text/html},
}
@misc{libackpack_C50,
        title = {{LiBackpack} {C50}-{GreenValley} {International}},
        url = {https://greenvalleyintl.com/LiBackpackC50/},
        urldate = {2022-09-19},
        file = {LiBackpack C50-GreenValley International:/home/mjpc13/Zotero/storage/HRK8J44G/LiBackpackC50.html:text/html},
}


%---In-House Apparatus---

@article{oveland_comparing_2018,
        title = {Comparing {Three} {Different} {Ground} {Based} {Laser} {Scanning} {Methods} for {Tree} {Stem} {Detection}},
        volume = {10},
        issn = {2072-4292},
        url = {https://dx.doi.org/10.3390/rs10040538},
        doi = {10.3390/rs10040538},
        number = {4},
        journal = {Remote Sensing},
        author = {Oveland, Ivar and Hauglin, Marius and Giannetti, Francesca and Schipper Kjørsvik, Narve and Gobakken, Terje},
        year = {2018},
        note = {Publisher: MDPI AG},
        pages = {538},
}

@article{su_development_2021,
        title = {The {Development} and {Evaluation} of a {Backpack} {LiDAR} {System} for {Accurate} and {Efficient} {Forest} {Inventory}},
        volume = {18},
        issn = {1545-598X},
        url = {https://dx.doi.org/10.1109/lgrs.2020.3005166},
        doi = {10.1109/lgrs.2020.3005166},
        number = {9},
        journal = {IEEE Geoscience and Remote Sensing Letters},
        author = {Su, Yanjun and Guo, Qinghua and Jin, Shichao and Guan, Hongcan and Sun, Xiliang and Ma, Qin and Hu, Tianyu and Wang, Rui and Li, Yumei},
        year = {2021},
        note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
        pages = {1660--1664},
}

@techreport{proudman_online_2021,
        title = {Online {Estimation} of {Diameter} at {Breast} {Height} ({DBH}) of {Forest} {Trees} {Using} a {Handheld} {LiDAR}},
        url = {http://arxiv.org/abs/2108.01552},
        abstract = {While mobile LiDAR sensors are increasingly used to scan in ecology and forestry applications, reconstruction and characterisation are typically carried out offline (to the best of our knowledge). Motivated by this, we present an online LiDAR system which can run on a handheld device to segment and track individual trees and identify them in a fixed coordinate system. Segments relating to each tree are accumulated over time, and tree models are completed as more scans are captured from different perspectives. Using this reconstruction we then fit a cylinder model to each tree trunk by solving a least-squares optimisation over the points to estimate the Diameter at Breast Height (DBH) of the trees. Experimental results demonstrate that our system can estimate DBH to within \${\textbackslash}sim\$7 cm accuracy for 90\% of individual trees in a forest (Wytham Woods, Oxford)},
        number = {arXiv:2108.01552},
        urldate = {2022-09-19},
        institution = {arXiv},
        author = {Proudman, Alexander and Ramezani, Milad and Fallon, Maurice},
        month = aug,
        year = {2021},
        note = {arXiv:2108.01552 [eess]
type: article},
        keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
        file = {arXiv Fulltext PDF:/home/mjpc13/Zotero/storage/ZHWQ69RS/Proudman et al. - 2021 - Online Estimation of Diameter at Breast Height (DB.pdf:application/pdf;arXiv.org Snapshot:/home/mjpc13/Zotero/storage/4VL5NQ4T/2108.html:text/html},
}

@article{xu_fast-lio_2021,
        title = {{FAST}-{LIO}: {A} {Fast}, {Robust} {LiDAR}-{Inertial} {Odometry} {Package} by {Tightly}-{Coupled} {Iterated} {Kalman} {Filter}},
        volume = {6},
        issn = {2377-3766},
        url = {https://dx.doi.org/10.1109/lra.2021.3064227},
        doi = {10.1109/lra.2021.3064227},
        number = {2},
        journal = {IEEE Robotics and Automation Letters},
        author = {Xu, Wei and Zhang, Fu},
        year = {2021},
        note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
        pages = {3317--3324},
}

@techreport{xu_fast-lio2_2021,
        title = {{FAST}-{LIO2}: {Fast} {Direct} {LiDAR}-inertial {Odometry}},
        shorttitle = {{FAST}-{LIO2}},
        url = {http://arxiv.org/abs/2107.06829},
        abstract = {This paper presents FAST-LIO2: a fast, robust, and versatile LiDAR-inertial odometry framework. Building on a highly efficient tightly-coupled iterated Kalman filter, FAST-LIO2 has two key novelties that allow fast, robust, and accurate LiDAR navigation (and mapping). The first one is directly registering raw points to the map (and subsequently update the map, i.e., mapping) without extracting features. This enables the exploitation of subtle features in the environment and hence increases the accuracy. The elimination of a hand-engineered feature extraction module also makes it naturally adaptable to emerging LiDARs of different scanning patterns; The second main novelty is maintaining a map by an incremental k-d tree data structure, ikd-Tree, that enables incremental updates (i.e., point insertion, delete) and dynamic re-balancing. Compared with existing dynamic data structures (octree, R*-tree, nanoflann k-d tree), ikd-Tree achieves superior overall performance while naturally supports downsampling on the tree. We conduct an exhaustive benchmark comparison in 19 sequences from a variety of open LiDAR datasets. FAST-LIO2 achieves consistently higher accuracy at a much lower computation load than other state-of-the-art LiDAR-inertial navigation systems. Various real-world experiments on solid-state LiDARs with small FoV are also conducted. Overall, FAST-LIO2 is computationally-efficient (e.g., up to 100 Hz odometry and mapping in large outdoor environments), robust (e.g., reliable pose estimation in cluttered indoor environments with rotation up to 1000 deg/s), versatile (i.e., applicable to both multi-line spinning and solid-state LiDARs, UAV and handheld platforms, and Intel and ARM-based processors), while still achieving higher accuracy than existing methods. Our implementation of the system FAST-LIO2, and the data structure ikd-Tree are both open-sourced on Github.},
        number = {arXiv:2107.06829},
        urldate = {2022-10-13},
        institution = {arXiv},
        author = {Xu, Wei and Cai, Yixi and He, Dongjiao and Lin, Jiarong and Zhang, Fu},
        month = jul,
        year = {2021},
        note = {arXiv:2107.06829 [cs]
type: article},
        keywords = {Computer Science - Robotics},
        file = {arXiv Fulltext PDF:/home/mjpc13/Zotero/storage/EN4V8SLY/Xu et al. - 2021 - FAST-LIO2 Fast Direct LiDAR-inertial Odometry.pdf:application/pdf;arXiv.org Snapshot:/home/mjpc13/Zotero/storage/KLERIRL3/2107.html:text/html},
}

@article{xiao_high-precision_2022,
        title = {High-{Precision} {SLAM} {Based} on the {Tight} {Coupling} of {Dual} {Lidar} {Inertial} {Odometry} for {Multi}-{Scene} {Applications}},
        volume = {12},
        doi = {10.3390/app12030939},
        abstract = {Simultaneous Localization and Mapping (SLAM) is an essential feature in many applications of mobile vehicles. To solve the problem of poor positioning accuracy, single use of mapping scene, and unclear structural characteristics in indoor and outdoor SLAM, a new framework of tight coupling of dual lidar inertial odometry is proposed in this paper. Firstly, through external calibration and an adaptive timestamp synchronization algorithm, the horizontal and vertical lidar data are fused, which compensates for the narrow vertical field of view (FOV) of the lidar and makes the characteristics of vertical direction more complete in the mapping process. Secondly, the dual lidar data is tightly coupled with an Inertial Measurement Unit (IMU) to eliminate the motion distortion of the dual lidar odometry. Then, the value of the lidar odometry after correcting distortion and the pre-integrated value of IMU are used as constraints to establish a non-linear least-squares objective function. Joint optimization is then performed to obtain the best value of the IMU state values, which will be used to predict the state of IMU at the next time step. Finally, experimental results are presented to verify the effectiveness of the proposed method.},
        journal = {Applied Sciences},
        author = {Xiao, Kui and Yu, Wentao and Liu, Weirong and Qu, Feng and Ma, Zhenyan},
        month = jan,
        year = {2022},
        pages = {939},
        file = {Full Text:/home/mjpc13/Zotero/storage/AUMX2X4M/Xiao et al. - 2022 - High-Precision SLAM Based on the Tight Coupling of.pdf:application/pdf},
}

@techreport{sier_benchmark_2022,
        title = {A {Benchmark} for {Multi}-{Modal} {Lidar} {SLAM} with {Ground} {Truth} in {GNSS}-{Denied} {Environments}},
        url = {http://arxiv.org/abs/2210.00812},
        abstract = {Lidar-based simultaneous localization and mapping (SLAM) approaches have obtained considerable success in autonomous robotic systems. This is in part owing to the high-accuracy of robust SLAM algorithms and the emergence of new and lower-cost lidar products. This study benchmarks current state-of-the-art lidar SLAM algorithms with a multi-modal lidar sensor setup showcasing diverse scanning modalities (spinning and solid-state) and sensing technologies, and lidar cameras, mounted on a mobile sensing and computing platform. We extend our previous multi-modal multi-lidar dataset with additional sequences and new sources of ground truth data. Specifically, we propose a new multi-modal multi-lidar SLAM-assisted and ICP-based sensor fusion method for generating ground truth maps. With these maps, we then match real-time pointcloud data using a natural distribution transform (NDT) method to obtain the ground truth with full 6 DOF pose estimation. This novel ground truth data leverages high-resolution spinning and solid-state lidars. We also include new open road sequences with GNSS-RTK data and additional indoor sequences with motion capture (MOCAP) ground truth, complementing the previous forest sequences with MOCAP data. We perform an analysis of the positioning accuracy achieved with ten different SLAM algorithm and lidar combinations. We also report the resource utilization in four different computational platforms and a total of five settings (Intel and Jetson ARM CPUs). Our experimental results show that current state-of-the-art lidar SLAM algorithms perform very differently for different types of sensors. More results, code, and the dataset can be found at: {\textbackslash}href\{https://github.com/TIERS/tiers-lidars-dataset-enhanced\}\{\vphantom{\}}github.com/TIERS/tiers-lidars-dataset-enhanced.},
        number = {arXiv:2210.00812},
        urldate = {2022-10-12},
        institution = {arXiv},
        author = {Sier, Ha and Qingqing, Li and Xianjia, Yu and Queralta, Jorge Peña and Zou, Zhuo and Westerlund, Tomi},
        month = oct,
        year = {2022},
        note = {arXiv:2210.00812 [cs]
type: article},
        keywords = {Computer Science - Robotics},
}